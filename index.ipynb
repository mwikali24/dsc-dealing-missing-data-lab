{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Dealing with Missing Data - Lab\n","\n","## Introduction\n","\n","In this lab, we'll work through strategies for data cleaning and dealing with missing values (`NaN`s).\n","\n","## Objectives\n","In this lab you will:\n","\n","- Identify missing values in a dataframe using built-in methods \n","- Explain why missing values are a problem in data science \n","\n","## Dataset\n","\n","In this lab, we'll continue working with the _Titanic Survivors_ dataset, which can be found in `'titanic.csv'`.\n","\n","Before we can get going, we'll need to import the usual libraries.  In the cell below, import:\n","* `pandas` as `pd`\n","* `numpy` as `np`\n","* `matplotlib.pyplot` as `plt`\n","* set `%matplotlib inline`"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Import necessary libraries below\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n"]},{"cell_type":"markdown","metadata":{},"source":["Now, let's get started by reading in the data from the `'titanic.csv'` file and storing it the DataFrame `df`. Subsequently, be sure to preview the data."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>886</th>\n","      <td>886</td>\n","      <td>887</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Montvila, Rev. Juozas</td>\n","      <td>male</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>211536</td>\n","      <td>13.0000</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>887</td>\n","      <td>888</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Graham, Miss. Margaret Edith</td>\n","      <td>female</td>\n","      <td>19.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>112053</td>\n","      <td>30.0000</td>\n","      <td>B42</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>888</td>\n","      <td>889</td>\n","      <td>0</td>\n","      <td>?</td>\n","      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n","      <td>female</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>W./C. 6607</td>\n","      <td>23.4500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>889</td>\n","      <td>890</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Behr, Mr. Karl Howell</td>\n","      <td>male</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>111369</td>\n","      <td>30.0000</td>\n","      <td>C148</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>890</td>\n","      <td>891</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Dooley, Mr. Patrick</td>\n","      <td>male</td>\n","      <td>32.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>370376</td>\n","      <td>7.7500</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows Ã— 13 columns</p>\n","</div>"],"text/plain":["     Unnamed: 0  PassengerId  Survived Pclass  \\\n","0             0            1         0      3   \n","1             1            2         1      1   \n","2             2            3         1      3   \n","3             3            4         1      1   \n","4             4            5         0      3   \n","..          ...          ...       ...    ...   \n","886         886          887         0      2   \n","887         887          888         1      1   \n","888         888          889         0      ?   \n","889         889          890         1      1   \n","890         890          891         0      3   \n","\n","                                                  Name     Sex   Age  SibSp  \\\n","0                              Braund, Mr. Owen Harris    male  22.0      1   \n","1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                               Heikkinen, Miss. Laina  female  26.0      0   \n","3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                             Allen, Mr. William Henry    male  35.0      0   \n","..                                                 ...     ...   ...    ...   \n","886                              Montvila, Rev. Juozas    male  27.0      0   \n","887                       Graham, Miss. Margaret Edith  female  19.0      0   \n","888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n","889                              Behr, Mr. Karl Howell    male  26.0      0   \n","890                                Dooley, Mr. Patrick    male  32.0      0   \n","\n","     Parch            Ticket     Fare Cabin Embarked  \n","0        0         A/5 21171   7.2500   NaN        S  \n","1        0          PC 17599  71.2833   C85        C  \n","2        0  STON/O2. 3101282   7.9250   NaN        S  \n","3        0            113803  53.1000  C123        S  \n","4        0            373450   8.0500   NaN        S  \n","..     ...               ...      ...   ...      ...  \n","886      0            211536  13.0000   NaN        S  \n","887      0            112053  30.0000   B42        S  \n","888      2        W./C. 6607  23.4500   NaN        S  \n","889      0            111369  30.0000  C148        C  \n","890      0            370376   7.7500   NaN        Q  \n","\n","[891 rows x 13 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Use pandas to load the csv file\n","df = pd.read_csv(\"titanic.csv\")\n","df\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["Unnamed: 0     False\n","PassengerId     True\n","Survived       False\n","Pclass          True\n","Name            True\n","Sex             True\n","Age             True\n","SibSp          False\n","Parch          False\n","Ticket          True\n","Fare           False\n","Cabin           True\n","Embarked        True\n","dtype: bool"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df.all()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  PassengerId  Survived Pclass  \\\n","0           0            1         0      3   \n","1           1            2         1      1   \n","2           2            3         1      3   \n","3           3            4         1      1   \n","4           4            5         0      3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>886</th>\n","      <td>886</td>\n","      <td>887</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Montvila, Rev. Juozas</td>\n","      <td>male</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>211536</td>\n","      <td>13.00</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>887</td>\n","      <td>888</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Graham, Miss. Margaret Edith</td>\n","      <td>female</td>\n","      <td>19.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>112053</td>\n","      <td>30.00</td>\n","      <td>B42</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>888</td>\n","      <td>889</td>\n","      <td>0</td>\n","      <td>?</td>\n","      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n","      <td>female</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>W./C. 6607</td>\n","      <td>23.45</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>889</td>\n","      <td>890</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Behr, Mr. Karl Howell</td>\n","      <td>male</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>111369</td>\n","      <td>30.00</td>\n","      <td>C148</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>890</td>\n","      <td>891</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Dooley, Mr. Patrick</td>\n","      <td>male</td>\n","      <td>32.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>370376</td>\n","      <td>7.75</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Unnamed: 0  PassengerId  Survived Pclass  \\\n","886         886          887         0      2   \n","887         887          888         1      1   \n","888         888          889         0      ?   \n","889         889          890         1      1   \n","890         890          891         0      3   \n","\n","                                         Name     Sex   Age  SibSp  Parch  \\\n","886                     Montvila, Rev. Juozas    male  27.0      0      0   \n","887              Graham, Miss. Margaret Edith  female  19.0      0      0   \n","888  Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1      2   \n","889                     Behr, Mr. Karl Howell    male  26.0      0      0   \n","890                       Dooley, Mr. Patrick    male  32.0      0      0   \n","\n","         Ticket   Fare Cabin Embarked  \n","886      211536  13.00   NaN        S  \n","887      112053  30.00   B42        S  \n","888  W./C. 6607  23.45   NaN        S  \n","889      111369  30.00  C148        C  \n","890      370376   7.75   NaN        Q  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.tail()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>714.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>445.000000</td>\n","      <td>446.000000</td>\n","      <td>0.383838</td>\n","      <td>29.699118</td>\n","      <td>0.523008</td>\n","      <td>0.381594</td>\n","      <td>32.204208</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>257.353842</td>\n","      <td>257.353842</td>\n","      <td>0.486592</td>\n","      <td>14.526497</td>\n","      <td>1.102743</td>\n","      <td>0.806057</td>\n","      <td>49.693429</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.420000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>222.500000</td>\n","      <td>223.500000</td>\n","      <td>0.000000</td>\n","      <td>20.125000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.910400</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>445.000000</td>\n","      <td>446.000000</td>\n","      <td>0.000000</td>\n","      <td>28.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>14.454200</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>667.500000</td>\n","      <td>668.500000</td>\n","      <td>1.000000</td>\n","      <td>38.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>31.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>890.000000</td>\n","      <td>891.000000</td>\n","      <td>1.000000</td>\n","      <td>80.000000</td>\n","      <td>8.000000</td>\n","      <td>6.000000</td>\n","      <td>512.329200</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Unnamed: 0  PassengerId    Survived         Age       SibSp  \\\n","count  891.000000   891.000000  891.000000  714.000000  891.000000   \n","mean   445.000000   446.000000    0.383838   29.699118    0.523008   \n","std    257.353842   257.353842    0.486592   14.526497    1.102743   \n","min      0.000000     1.000000    0.000000    0.420000    0.000000   \n","25%    222.500000   223.500000    0.000000   20.125000    0.000000   \n","50%    445.000000   446.000000    0.000000   28.000000    0.000000   \n","75%    667.500000   668.500000    1.000000   38.000000    1.000000   \n","max    890.000000   891.000000    1.000000   80.000000    8.000000   \n","\n","            Parch        Fare  \n","count  891.000000  891.000000  \n","mean     0.381594   32.204208  \n","std      0.806057   49.693429  \n","min      0.000000    0.000000  \n","25%      0.000000    7.910400  \n","50%      0.000000   14.454200  \n","75%      0.000000   31.000000  \n","max      6.000000  512.329200  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.describe()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 891 entries, 0 to 890\n","Data columns (total 13 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   Unnamed: 0   891 non-null    int64  \n"," 1   PassengerId  891 non-null    int64  \n"," 2   Survived     891 non-null    int64  \n"," 3   Pclass       891 non-null    object \n"," 4   Name         891 non-null    object \n"," 5   Sex          891 non-null    object \n"," 6   Age          714 non-null    float64\n"," 7   SibSp        891 non-null    int64  \n"," 8   Parch        891 non-null    int64  \n"," 9   Ticket       891 non-null    object \n"," 10  Fare         891 non-null    float64\n"," 11  Cabin        204 non-null    object \n"," 12  Embarked     889 non-null    object \n","dtypes: float64(2), int64(5), object(6)\n","memory usage: 90.6+ KB\n"]}],"source":["df.info()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["Unnamed: 0       0\n","PassengerId      0\n","Survived         0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age            177\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","Cabin          687\n","Embarked         2\n","dtype: int64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["## Find missing values in a DataFrame\n","\n","Before we can deal with missing values, we first need to find them. There are several easy ways to detect them.  We will start by answering very general questions, such as \"does this DataFrame contain any null values?\", and then narrowing our focus each time the answer to a question is \"yes\".\n","\n","We'll start by checking to see if the DataFrame contains **any** missing values (NaNs) at all. \n","\n","**_Hint_**: If you do this correctly, it will require method chaining, and will return a boolean value for each column.  "]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["Unnamed: 0     False\n","PassengerId    False\n","Survived       False\n","Pclass         False\n","Name           False\n","Sex            False\n","Age             True\n","SibSp          False\n","Parch          False\n","Ticket         False\n","Fare           False\n","Cabin           True\n","Embarked        True\n","dtype: bool"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","df.isnull().any()\n"]},{"cell_type":"markdown","metadata":{},"source":["Now we know which columns contain missing values, but not how many. \n","\n","In the cell below, chain a different method with `isna()` to check how many total missing values are in each column.  \n","\n","Expected Output:\n","\n","```\n","PassengerId      0\n","Survived         0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age            177\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","Cabin          687\n","Embarked         2\n","dtype: int64\n","```"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["Unnamed: 0       0\n","PassengerId      0\n","Survived         0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age            177\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","Cabin          687\n","Embarked         2\n","dtype: int64"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","df.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["Now that we know how many missing values exist in each column, we can make some decisions about how to deal with them.  \n","\n","We'll deal with each column individually, and employ a different strategy for each.  \n","\n","\n","### Dropping the column\n","\n","The first column we'll deal with is the `Cabin` column.  We'll begin by examining this column more closely. \n","\n","\n","In the cell below:\n","* Determine what percentage of rows in this column contain missing values\n","* Print out the number of unique values in this column"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["(891, 13)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["687"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","df['Cabin'].isnull().sum()\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["77.10437710437711"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["((df[\"Cabin\"].isnull().sum())/len(df[\"Cabin\"]))* 100"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["missing_count = df.isnull().sum().sort_values(ascending=False)\n","missing_percentage = (((df.isnull().sum())/len(df))* 100).sort_values(ascending = False)\n","missing_df = pd.DataFrame({ \"missing\": missing_count,\"percentage\":missing_percentage},index = missing_count.index)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>missing</th>\n","      <th>percentage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Cabin</th>\n","      <td>687</td>\n","      <td>77.104377</td>\n","    </tr>\n","    <tr>\n","      <th>Age</th>\n","      <td>177</td>\n","      <td>19.865320</td>\n","    </tr>\n","    <tr>\n","      <th>Embarked</th>\n","      <td>2</td>\n","      <td>0.224467</td>\n","    </tr>\n","    <tr>\n","      <th>Fare</th>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Ticket</th>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Parch</th>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>SibSp</th>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Sex</th>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Name</th>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Pclass</th>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Survived</th>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Unnamed: 0</th>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             missing  percentage\n","Cabin            687   77.104377\n","Age              177   19.865320\n","Embarked           2    0.224467\n","Fare               0    0.000000\n","Ticket             0    0.000000\n","Parch              0    0.000000\n","SibSp              0    0.000000\n","Sex                0    0.000000\n","Name               0    0.000000\n","Pclass             0    0.000000\n","Survived           0    0.000000\n","PassengerId        0    0.000000\n","Unnamed: 0         0    0.000000"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["missing_df"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["Unnamed: 0     891\n","PassengerId    891\n","Survived         2\n","Pclass           4\n","Name           891\n","Sex              2\n","Age             88\n","SibSp            7\n","Parch            7\n","Ticket         681\n","Fare           248\n","Cabin          147\n","Embarked         3\n","dtype: int64"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df.nunique()"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["array([nan, 'C85', 'C123', 'E46', 'G6', 'C103', 'D56', 'A6',\n","       'C23 C25 C27', 'B78', 'D33', 'B30', 'C52', 'B28', 'C83', 'F33',\n","       'F G73', 'E31', 'A5', 'D10 D12', 'D26', 'C110', 'B58 B60', 'E101',\n","       'F E69', 'D47', 'B86', 'F2', 'C2', 'E33', 'B19', 'A7', 'C49', 'F4',\n","       'A32', 'B4', 'B80', 'A31', 'D36', 'D15', 'C93', 'C78', 'D35',\n","       'C87', 'B77', 'E67', 'B94', 'C125', 'C99', 'C118', 'D7', 'A19',\n","       'B49', 'D', 'C22 C26', 'C106', 'C65', 'E36', 'C54',\n","       'B57 B59 B63 B66', 'C7', 'E34', 'C32', 'B18', 'C124', 'C91', 'E40',\n","       'T', 'C128', 'D37', 'B35', 'E50', 'C82', 'B96 B98', 'E10', 'E44',\n","       'A34', 'C104', 'C111', 'C92', 'E38', 'D21', 'E12', 'E63', 'A14',\n","       'B37', 'C30', 'D20', 'B79', 'E25', 'D46', 'B73', 'C95', 'B38',\n","       'B39', 'B22', 'C86', 'C70', 'A16', 'C101', 'C68', 'A10', 'E68',\n","       'B41', 'A20', 'D19', 'D50', 'D9', 'A23', 'B50', 'A26', 'D48',\n","       'E58', 'C126', 'B71', 'B51 B53 B55', 'D49', 'B5', 'B20', 'F G63',\n","       'C62 C64', 'E24', 'C90', 'C45', 'E8', 'B101', 'D45', 'C46', 'D30',\n","       'E121', 'D11', 'E77', 'F38', 'B3', 'D6', 'B82 B84', 'D17', 'A36',\n","       'B102', 'B69', 'E49', 'C47', 'D28', 'E17', 'A24', 'C50', 'B42',\n","       'C148'], dtype=object)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df[\"Cabin\"].unique()"]},{"cell_type":"markdown","metadata":{},"source":["With this many missing values, it's probably best for us to just drop this column completely.\n","\n","In the cell below:\n","\n","* Drop the `Cabin` column in place from the `df` DataFrame\n","* Then, check the remaining number of null values in the dataset by using the code you wrote previously   "]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# Your code here\n","df.drop(columns = \"Cabin\",inplace = True)\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 891 entries, 0 to 890\n","Data columns (total 12 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   Unnamed: 0   891 non-null    int64  \n"," 1   PassengerId  891 non-null    int64  \n"," 2   Survived     891 non-null    int64  \n"," 3   Pclass       891 non-null    object \n"," 4   Name         891 non-null    object \n"," 5   Sex          891 non-null    object \n"," 6   Age          714 non-null    float64\n"," 7   SibSp        891 non-null    int64  \n"," 8   Parch        891 non-null    int64  \n"," 9   Ticket       891 non-null    object \n"," 10  Fare         891 non-null    float64\n"," 11  Embarked     889 non-null    object \n","dtypes: float64(2), int64(5), object(5)\n","memory usage: 83.7+ KB\n"]}],"source":["df.info()"]},{"cell_type":"markdown","metadata":{},"source":["### Computing placeholder values\n","\n","Recall that another common strategy for dealing with missing values is to replace them with the mean or median for that column. We'll begin by investigating the current version of the `'Age'` column.  \n","\n","In the cell below:\n","\n","* Plot a histogram of values in the `'Age'` column with 80 bins (1 for each year)    \n","* Print out the mean and median for the column   "]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\HP\\anaconda3\\envs\\learn-env\\lib\\site-packages\\numpy\\lib\\histograms.py:839: RuntimeWarning: invalid value encountered in greater_equal\n","  keep = (tmp_a >= first_edge)\n","c:\\Users\\HP\\anaconda3\\envs\\learn-env\\lib\\site-packages\\numpy\\lib\\histograms.py:840: RuntimeWarning: invalid value encountered in less_equal\n","  keep &= (tmp_a <= last_edge)\n"]},{"data":{"text/plain":["<function matplotlib.pyplot.show(close=None, block=None)>"]},"execution_count":20,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Your code here\n","plt.figure(figsize = (12,6))\n","plt.hist(df[\"Age\"],bins =80,)\n","plt.xlabel = \"Age\"\n","plt.ylabel = \"Frequency\"\n","plt.title = \"Age versus Frequency\"\n","plt.show\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean 29.69911764705882\n","Median 28.0\n"]}],"source":["print(\"Mean\",df[\"Age\"].mean())\n","print(\"Median\",df[\"Age\"].median())"]},{"cell_type":"markdown","metadata":{},"source":["From the visualization above, we can see the data has a slightly positive skew. \n","\n","In the cell below, replace all missing values in the `'Age'` column with the median of the column.  **Do not hard code this value -- use the methods from pandas or numpy to make this easier.**  Do this replacement in place on the DataFrame. "]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["0      22.0\n","1      38.0\n","2      26.0\n","3      35.0\n","4      35.0\n","       ... \n","886    27.0\n","887    19.0\n","888    28.0\n","889    26.0\n","890    32.0\n","Name: Age, Length: 891, dtype: float64"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","df[\"Age\"] =df[\"Age\"].replace(to_replace = np.nan, value =df[\"Age\"].median())\n","df[\"Age\"] \n"]},{"cell_type":"markdown","metadata":{},"source":["Now that we've replaced the values in the `'Age'` column, let's confirm that they've been replaced.  \n","\n","In the cell below, check how many null values remain in the dataset.  "]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["Unnamed: 0     0\n","PassengerId    0\n","Survived       0\n","Pclass         0\n","Name           0\n","Sex            0\n","Age            0\n","SibSp          0\n","Parch          0\n","Ticket         0\n","Fare           0\n","Embarked       2\n","dtype: int64"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","df.isnull().sum()\n"]},{"cell_type":"markdown","metadata":{},"source":["Now we need to deal with the two pesky missing values in the `'Embarked'` column.  \n","\n","### Dropping rows that contain missing values\n","\n","Perhaps the most common solution to dealing with missing values is to simply drop any rows that contain them.  Of course, this is only a good idea if the number dropped does not constitute a significant portion of our dataset.  Often, you'll need to make the overall determination to see if dropping the values is an acceptable loss, or if it is a better idea to just drop an offending column (e.g. the `'Cabin'` column) or to impute placeholder values instead.\n","\n","In the cell below, use the appropriate built-in DataFrame method to drop the rows containing missing values. Do this in place on the DataFrame.  "]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["# Your code here\n","df.dropna(how = \"any\",inplace = True)\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["(889, 12)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 889 entries, 0 to 890\n","Data columns (total 12 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   Unnamed: 0   889 non-null    int64  \n"," 1   PassengerId  889 non-null    int64  \n"," 2   Survived     889 non-null    int64  \n"," 3   Pclass       889 non-null    object \n"," 4   Name         889 non-null    object \n"," 5   Sex          889 non-null    object \n"," 6   Age          889 non-null    float64\n"," 7   SibSp        889 non-null    int64  \n"," 8   Parch        889 non-null    int64  \n"," 9   Ticket       889 non-null    object \n"," 10  Fare         889 non-null    float64\n"," 11  Embarked     889 non-null    object \n","dtypes: float64(2), int64(5), object(5)\n","memory usage: 90.3+ KB\n"]}],"source":["df.info()"]},{"cell_type":"markdown","metadata":{},"source":["We've dealt with all the **_obvious_** missing values, but we should also take some time to make sure that there aren't symbols or numbers included that are meant to denote a missing value. \n","\n","### Missing values with placeholders\n","\n","A common thing to see when working with datasets is missing values denoted with a preassigned code or symbol.  Let's check to ensure that each categorical column contains only what we expect.\n","\n","In the cell below, return the unique values in the `'Embarked'`, `'Sex'`, `'Pclass'`, and `'Survived'` columns to ensure that there are no values in there that we don't understand or can't account for.  "]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['S' 'C' 'Q']\n","['male' 'female']\n","['3' '1' '2' '?']\n","[0 1]\n"]}],"source":["# Your code here\n","print(df[\"Embarked\"].unique())\n","print(df[\"Sex\"].unique())\n","print(df[\"Pclass\"].unique())\n","print(df[\"Survived\"].unique())\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["It looks like the `'Pclass'` column contains some missing values denoted by a placeholder. \n","\n","In the cell below, investigate how many placeholder values this column contains.  Then, deal with these missing values using whichever strategy you believe is most appropriate in this case.  "]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["0        3\n","1        1\n","2        3\n","3        1\n","4        3\n","      ... \n","886      2\n","887      1\n","888    NaN\n","889      1\n","890      3\n","Name: Pclass, Length: 889, dtype: object"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","df[\"Pclass\"]= np.where(np.array(df[\"Pclass\"]) == \"?\" ,np.nan,df[\"Pclass\"])\n","df[\"Pclass\"]"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["Unnamed: 0      0\n","PassengerId     0\n","Survived        0\n","Pclass         48\n","Name            0\n","Sex             0\n","Age             0\n","SibSp           0\n","Parch           0\n","Ticket          0\n","Fare            0\n","Embarked        0\n","dtype: int64"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","df.isnull().sum()\n","\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["0      3\n","1      1\n","2      3\n","3      1\n","4      3\n","      ..\n","886    2\n","887    1\n","888    3\n","889    1\n","890    3\n","Name: Pclass, Length: 889, dtype: object"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["df['Pclass'] = df['Pclass'].replace(to_replace = np.nan, value = df['Pclass'].median())\n","df['Pclass']\n"]},{"cell_type":"markdown","metadata":{},"source":["**_Question:_** What is the benefit of treating missing values as a separate valid category?  What is the benefit of removing or replacing them? What are the drawbacks of each? Finally, which strategy did you choose? Explain your choice below. \n","\n","Write your answer below this line:\n","______________________________________________________________________________________________________"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","    <summary style=\"cursor: pointer; display: inline\">\n","        <b><u>Solution (click to reveal)</u></b>\n","    </summary>\n","    <p>Sample response:\n","\n","By treating missing values as a separate category, information is preserved. \n","Perhaps there is a reason that this information is missing. \n","By removing or replacing missing information, we can more easily conduct mathematical analyses which require values for computation. \n","I chose to randomly replace for now. I could have just as easily removed the data. \n","Concerns include that I imputed the wrong value (indeed it was a random guess). \n","The strategy for dealing with missing data will depend on our desired application, \n","but regardless of the approach taken, the ramifications of how missing data are handled must be considered. \n","For example, imputing the median of our age reduces variance \n","and assumes that a new value would be close to the center of the distribution \n","(albeit this assumption is statistically likely).</p>\n","</details>"]},{"cell_type":"markdown","metadata":{},"source":["Now, let's do a final check to ensure that there are no more missing values remaining in this dataset.  \n","\n","In the cell below, reuse the code you wrote at the beginning of the notebook to check how many null values our dataset now contains.  "]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/plain":["Unnamed: 0     False\n","PassengerId    False\n","Survived       False\n","Pclass         False\n","Name           False\n","Sex            False\n","Age            False\n","SibSp          False\n","Parch          False\n","Ticket         False\n","Fare           False\n","Embarked       False\n","dtype: bool"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","df.isnull().any()\n"]},{"cell_type":"markdown","metadata":{},"source":["Those all seem in line with our expectations.  We can confidently say that this dataset contains no pesky missing values that will mess up our analysis if we continue with this dataset."]},{"cell_type":"markdown","metadata":{},"source":["## Summary\n","\n","In this lab, we learned:\n","* How to detect missing values in our dataset\n","* How to deal with missing values by dropping rows\n","* How to deal with missing values by imputing mean/median values \n","* Strategies for detecting missing values encoded with a placeholder"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":2}
